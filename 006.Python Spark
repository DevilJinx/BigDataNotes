Python Spark:
安装Scala：
wget http://www.scala-lang.org/files/archive/scala-2.11.6.tgz
tar xvf scala-2.11.6.tgz
mv scala-2.11.6 /usr/local/scala
vi /etc/profile:
#SCALA_PATH-----------------------
export SCALA_HOME=/usr/local/scala
export PATH=$PATH:$SCALA_HOME/bin

source /etc/profile

安装Spark:
wget https://archive.apache.org/dist/spark/spark-2.0.2/spark-2.0.2-bin-hadoop2.7.tgz
tar zxf spark-2.0.2-bin-hadoop2.7.tgz
mv spark-2.0.2-bin-hadoop2.7 /usr/local/spark
vi /etc/profile:
#SPARK_PATH-----------------------
export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin

source /etc/profile

启动pyspark交互式界面：
pyspark
离开pyspark交互式界面：
exit()
设置pyspark显示信息：
cd /usr/local/spark/conf
cp log4j.properties.template log4j.properties
vi log4j.properties:
INFO改为WARN
再次启动pyspark，信息少了很多，只列出重要部分信息

创建测试用的文本文件：
cp /opt/software/hYadoop-2.8.1/LICENSE.txt ~/wordcount/input/